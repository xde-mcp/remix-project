import { Monaco } from '@monaco-editor/react'

// A type representing a single type file (.d.ts) to be added to the Monaco editor, containing its virtual path and content.
type Library = { filePath: string; content: string }

// A type defining the minimum required fields from a package.json for type loading.
type PackageJson = {
  name?: string
  version?: string
  types?: string
  typings?: string
  exports?: string | Record<string, any>
}
type ResolveResult = { finalUrl: string; content: string }

const CDN_BASE = 'https://cdn.jsdelivr.net/npm/'
const VIRTUAL_BASE = 'file:///node_modules/'
const IMPORT_ANY_RE = /(?:import|export)\s+[^'"]*?from\s*['"]([^'"]+)['"]|import\s*['"]([^'"]+)['"]|require\(\s*['"]([^'"]+)['"]\s*\)/g
const TRIPLE_SLASH_REF_RE = /\/\/\/\s*<reference\s+path=["']([^"']+)["']\s*\/>/g

function isRelative(p: string): boolean {
  return p.startsWith('./') || p.startsWith('../') || p.startsWith('/')
}

// Extracts the base package name from an import path (e.g., 'viem/chains' -> 'viem').
function normalizeBareSpecifier(p: string): string {
  if (!p) return p
  if (p.startsWith('@')) return p.split('/').slice(0, 2).join('/')
  return p.split('/')[0]
}

// Function to generate @types package names, includes logic to prevent infinite recursion.
function toTypesScopedName(pkg: string): string {
  if (pkg.startsWith('@types/')) return pkg
  if (pkg.startsWith('@')) return '@types/' + pkg.slice(1).replace('/', '__')
  return '@types/' + pkg
}

// Converts a CDN URL to a virtual file system path used by the Monaco editor.
function toVirtual(url: string): string {
  return url.replace(CDN_BASE, VIRTUAL_BASE)
}

function stripJsLike(url: string): string {
  return url.replace(/\.d\.[mc]?ts$/, '').replace(/\.[mc]?ts$/, '').replace(/\.[mc]?js$/, '')
}

async function fetchJson<T = any>(url: string): Promise<T> {
  const res = await fetch(url)
  if (!res.ok) throw new Error(`HTTP ${res.status} for ${url}`)
  return res.json()
}

// Guesses a list of potential TypeScript Definition file (.d.ts) paths from a given JS-like file path.
// For example, 'index.js' is converted to 'index.d.ts', 'index.ts', 'index/index.d.ts', etc.
function guessDtsFromJs(jsPath: string): string[] {
  const base = stripJsLike(jsPath)
  return [`${base}.d.ts`, `${base}.ts`, `${base}/index.d.ts`, `${base}/index.ts`]
}

function buildExportTypeMap(pkgName: string, pkgJson: PackageJson): Record<string, string[]> {
  const map: Record<string, string[]> = {}
  const base = `${CDN_BASE}${pkgName}/`
  const push = (subpath: string, relPath: string | undefined) => {
    if (!relPath) return

    // [DEBUG] Check what values are being passed to the push function.
    console.log(`[DEBUG] push called with: subpath='${subpath}', relPath='${relPath}'`)

    if (/\.d\.[mc]?ts$/.test(relPath)) {
      // [DEBUG] Case when using the declaration file path directly.
      console.log(`[DEBUG] Direct declaration path matched for '${relPath}'. Using it as is.`)
      map[subpath] = [new URL(relPath, base).href]
    } else {
      // [DEBUG] Case when guessing based on a JS file path.
      console.log(`[DEBUG] Guessing declaration path for '${relPath}'.`)
      map[subpath] = guessDtsFromJs(relPath).map(a => new URL(a, base).href)
    }
  }

  if (pkgJson.exports) {
    const exports = pkgJson.exports as Record<string, any>

    // [DEBUG] Check the value of exports.types.
    console.log(`[DEBUG] Checking exports.types:`, exports.types)

    if (exports.types) {
      push('.', exports.types)
      
      // [DEBUG] Check the state of the map object after processing exports.types.
      console.log(`[DEBUG] Map state after exports.types:`, JSON.stringify(map, null, 2))
      return map
    }
    
    if (typeof exports === 'object') {
      for (const [subpath, condition] of Object.entries(exports)) {
        if (typeof condition === 'object' && condition !== null) {
          if (condition.types) {
            push(subpath, condition.types)
          } else {
            push(subpath, condition.import || condition.default)
          }
        } else if (typeof condition === 'string') {
          push(subpath, condition)
        }
      }
    }
  }

  if (Object.keys(map).length === 0 && (pkgJson.types || pkgJson.typings)) {
    // [DEBUG] Case when using the top-level types field.
    console.log(`[DEBUG] Falling back to top-level types field:`, pkgJson.types || pkgJson.typings)
    push('.', pkgJson.types || pkgJson.typings)
  }

  // [DEBUG] Check the final state of the map object just before returning.
  console.log(`[DEBUG] Final map state for '${pkgName}':`, JSON.stringify(map, null, 2))
  return map
}

// Given an array of candidate URLs, this function tries to fetch each one sequentially and returns the content of the first successful request.
// This is used to find the correct file from the list of possibilities generated by 'guessDtsFromJs'.
async function tryFetchOne(urls: string[]): Promise<ResolveResult | null> {
  for (const u of [...new Set(urls)]) {
    try {
      const r = await fetch(u); if (r.ok) return { finalUrl: u, content: await r.text() }
    } catch (e) {}
  }
  return null
}

// A crawler that recursively follows imports/exports within a type definition file (.d.ts).
async function crawl(entryUrl: string, pkgName: string, visited: Set<string>, enqueuePackage: (name: string) => void): Promise<Library[]> {
  if (visited.has(entryUrl)) return []
  visited.add(entryUrl)
  const out: Library[] = []
  try {
    // Check if the entryUrl is already a type declaration file.
    const urlsToTry = /\.d\.[mc]?ts$/.test(entryUrl)
      ? [entryUrl] // If yes, use only that URL without guessing.
      : guessDtsFromJs(entryUrl) // Otherwise, guess the paths.

    const res = await tryFetchOne(urlsToTry)
    if(!res) return []
    
    const { finalUrl, content } = res
    out.push({ filePath: toVirtual(finalUrl), content })
    const subPromises: Promise<Library[]>[] = []
    const crawlNext = (nextUrl: string) => {
      if (!visited.has(nextUrl)) subPromises.push(crawl(nextUrl, pkgName, visited, enqueuePackage))
    }
    // Handles triple-slash directives like '/// <reference ... />'.
    for (const m of content.matchAll(TRIPLE_SLASH_REF_RE)) crawlNext(new URL(m[1], finalUrl).href)
    for (const m of content.matchAll(IMPORT_ANY_RE)) {
      const spec = (m[1] || m[2] || m[3] || '').trim()
      if (!spec) continue
      // Continues crawling for relative path imports, and queues up external package imports.
      if (isRelative(spec)) crawlNext(new URL(spec, finalUrl).href)
      else {
        const bare = normalizeBareSpecifier(spec)
        // Ignores Node.js built-in modules that use the 'node:' protocol.
        if (bare && !bare.startsWith('node:')) enqueuePackage(bare)
      }
    }
    const results = await Promise.all(subPromises)
    results.forEach(arr => out.push(...arr))
  } catch (e) {
    // console.error(`Crawl failed for ${entryUrl}:`, e) // Optional: for deeper debugging
  }
  return out
}

// [3/4] The core service that, upon request from 'editor.ts', fetches type definitions (.d.ts) for NPM packages from a CDN.
export async function startTypeLoadingProcess(packageName: string): Promise<{ mainVirtualPath: string; libs: Library[]; subpathMap: Record<string, string> } | void> {
  const visitedPackages = new Set<string>()
  const collected: Library[] = []
  const subpathMap: Record<string, string> = {}

  // The core inner function that recursively loads a package and its dependencies. 
  async function loadPackage(pkgNameToLoad: string) {
  if (visitedPackages.has(pkgNameToLoad)) return
  visitedPackages.add(pkgNameToLoad)
  
  let pkgJson: PackageJson
  try {
    const pkgJsonUrl = new URL('package.json', `${CDN_BASE}${pkgNameToLoad}/`).href
    pkgJson = await fetchJson<PackageJson>(pkgJsonUrl)
  } catch (e) {
    console.log(`- Package '${pkgNameToLoad}' not found. Attempting @types fallback.`)
    // If the package is not found, attempt to find its @types equivalent.
    try { await loadPackage(toTypesScopedName(pkgNameToLoad)) } catch (ee) {}
    return
  }

  const exportMap = buildExportTypeMap(pkgNameToLoad, pkgJson)

  // If the package is found but contains no type information, attempt the @types fallback.
  if (Object.keys(exportMap).length === 0) {
    console.log(`- No type declarations in '${pkgNameToLoad}'. Attempting @types fallback.`)
    try { await loadPackage(toTypesScopedName(pkgNameToLoad)) } catch (ee) {}
    return
  }
  
  console.log(`[LOG 1] Starting full analysis for package: '${pkgNameToLoad}'`)
  const pendingDependencies = new Set<string>()
  const enqueuePackage = (p: string) => { if (!visitedPackages.has(p)) pendingDependencies.add(p) }
  
  const crawlPromises: Promise<Library[]>[] = []
  // Crawl all entry points of the package to gather complete type information.
  for (const [subpath, urls] of Object.entries(exportMap)) {
    const entryPointUrl = urls[0]
    if (entryPointUrl) {
      const pkgNameWithoutVersion = pkgNameToLoad.replace(/@[\^~]?[\d\.\w-]+$/, '')
      const virtualPathKey = subpath === '.' ? pkgNameWithoutVersion : `${pkgNameWithoutVersion}/${subpath.replace('./', '')}`

      subpathMap[virtualPathKey] = entryPointUrl.replace(CDN_BASE, '')
      crawlPromises.push(crawl(entryPointUrl, pkgNameToLoad, new Set<string>(), enqueuePackage))
    }
  }

  const libsArrays = await Promise.all(crawlPromises)
  libsArrays.forEach(libs => collected.push(...libs))
  
  // Recursively load any discovered dependency packages.
  if (pendingDependencies.size > 0) {
    console.log(`- Found dependencies for '${pkgNameToLoad}': ${Array.from(pendingDependencies).join(', ')}`)
    await Promise.all(Array.from(pendingDependencies).map(loadPackage))
  }
}

  await loadPackage(packageName)

  const mainVirtualPath = subpathMap[packageName] ? `${VIRTUAL_BASE}${subpathMap[packageName]}` : ''
  const finalPackages = [...new Set(collected.map(lib => normalizeBareSpecifier(lib.filePath.replace(VIRTUAL_BASE, ''))))]
  console.log(`[LOG 2] Full analysis complete. Total files: ${collected.length}. Packages loaded: ${finalPackages.join(', ')}`)

  return { mainVirtualPath, libs: collected, subpathMap }
}